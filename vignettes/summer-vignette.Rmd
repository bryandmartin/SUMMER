---
title: "Spatio-temporal Under-five Mortality Methods for Estimation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Spatio-temporal Under-five Mortality Methods for Estimation}
  %\usepackage[utf8]{inputenc}
---

```{r, echo = FALSE}
# Uncomment to enter DEBUG mode. The package vignette will compile, but code will not be evaluated for speed purposes.
# knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(fig.width=9, fig.height=5, out.width = '100%') 

```

## Load Package and Data


`DemoData` contains model survey data provided by DHS. Note that this data is fake, and does not represent any real country's data. Data similar to the `DemoData` data used in this vignette can be obtained by using  `getBirths`. `DemoMap` contains geographic data from the 1995 Uganda Admin 1 regions defined by DHS. Data similar to the `DemoMap` data used in this vignette can be obtained by using `read_shape`.

First, we load the package and load the necessary data. INLA is not in a standard repository, so we check if it is available and install it if it is not.

```{r, message = FALSE}
library(SUMMER)
if (!isTRUE(requireNamespace("INLA", quietly = TRUE))) {
  install.packages('INLA', repos = 'https://www.math.ntnu.no/inla/R/stable')
}

data(DemoData)
data(DemoMap)
```

`DemoData` is a list of $5$ data frames where each row represent one person-month record and contains the $8$ variables as shown below. Notice that `time` variable is turned into 5-year bins from `80-84` to `10-14`. 

```{r, message=FALSE}
summary(DemoData)
head(DemoData[[1]])
```

`DemoData` is obtained by processing the raw DHS birth data (in .dta format) in R. The raw file of birth recodes can be downloaded from the DHS website [https://dhsprogram.com/data/Download-Model-Datasets.cfm](https://dhsprogram.com/data/Download-Model-Datasets.cfm). For this example dataset, no registration is needed. For real DHS survey datasets, permission to access needs to be registered with DHS directly. `DemoData` contains a small sample of the observations in this dataset randomly assigned to $5$ example DHS surveys.

Here we demonstrate how to split the raw data into person-month format from. Notice that to read the file from early version of stata, the package `readstata13` is required. The following script is based on the example dataset `ZZBR62FL.DTA` available from the DHS website. We use the interaction of v024 and v025 as the strata indicator for the purpose of demonstration.

```{r, message=FALSE, eval=FALSE}
library(readstata13)
my_fp <- "data/ZZBR62DT/ZZBR62FL.DTA" 
dat <- getBirths(filepath = my_fp, surveyyear = 2015, strata = c("v024", "v025")) 
dat <- dat[,c("v001","v002","v024","per5","ageGrpD","v005","strata","died")]
colnames(dat) <- c("clustid","id","region","time","age","weights","strata","died")
```

## Make Country Summary

Next, we obtain Horvitz-Thompson estimators using `countrySummary_mult`.


```{r, warning=FALSE}
years <- levels(DemoData[[1]]$time)

data <- countrySummary_mult(births = DemoData, years = years, idVar = "id", regionVar = "region",
                           timeVar = "time", clusterVar = "~clustid+id", ageVar = "age",
                           weightsVar = "weights", geo.recode = NULL)
```

## Read Maps

In this step, we separate the output from `read_shape` to use as function arguments.

```{r, message = FALSE}
    geo <- DemoMap$geo
    mat <- DemoMap$Amat
```


## Make Priors

Using our adjacency matrix, we simulate hyperpriors using `simhyper`. The default INLA analysis scales the marginal variance of all structured random effects, so we only need to one set of hyperparameters with `only.iid` set to true. 

```{r}
priors <- simhyper(R = 2, nsamp = 1e+05, nsamp.check = 5000, Amat = mat, only.iid = TRUE)
```


## Prepare data for meta analysis
Before fitting the model, we first aggregate estimators from different surveys. 

```{r}
dim(data)
data <- aggregateSurvey(data)
dim(data)
```


## Fit INLA Model for national estimates
Now we are ready to fit the models. The codes to perform the new model fitting is attached at the end of this documentation.

First, we ignore the subnational estimates, and fit a model with temporal random effects only. In this part, we use the subset of data region variable being "All". 

### Period model
In fitting this model, we first define the list of time periods we wish to project the estimates on. First we can fit a Random Walk 2 only model defined on the 5-year period.

```{r, message = FALSE}
years.all <- c(years, "15-19")
fit1 <- fitINLA(data = data, geo = NULL, Amat = NULL, year_names = years.all,
                year_range = c(1985, 2019), priors = priors, rw = 2,
                is.yearly=FALSE, m = 5)
```

### Yearly model
Similarly as before, we can estimate the Random Walk 2 random effects on the yearly scale. 
```{r, message = FALSE}
fit2 <- fitINLA(data = data, geo = NULL, Amat = NULL, year_names = years.all,
                year_range = c(1985, 2019), priors = priors, rw = 2,
                is.yearly=TRUE, m = 5)
```

### Obtain smoothed estimates
The marginal posteriors are already stored in the fitted object. We use the following function to extract and re-arrange them.

```{r}
out1 <- projINLA(fit1, is.yearly = FALSE)
out2 <- projINLA(fit2, is.yearly = TRUE)
```

We can compare the results visually using the function below.

```{r}
library(ggplot2)
library(gridExtra)
g <- NULL
g[[1]] <- plot(out1, is.yearly=FALSE, is.subnational=FALSE) + ggtitle("National period model")
g[[2]] <- plot(out2, is.yearly=TRUE, is.subnational=FALSE) + ggtitle("National yearly model")
grid.arrange(grobs=g, ncol = 2)
```



## Fit INLA model for subnational estimates
Similarly we can fit the full model on all subnational regions. 

### Period model

```{r, message = FALSE}
fit3 <- fitINLA(data = data, geo = geo, Amat = mat, year_names = years.all,
                year_range = c(1985, 2019), priors = priors, rw = 2,
                is.yearly=FALSE)
out3 <- projINLA(fit3, Amat = mat, is.yearly = FALSE)
```

### Yearly model with type IV interaction
```{r, message = FALSE}
fit4 <- fitINLA(data = data, geo = geo, Amat = mat, year_names = years.all,
                year_range = c(1985, 2019), priors = priors, rw = 2,
                is.yearly=TRUE, m = 5, type.st = 4)
out4 <- projINLA(fit4, Amat = mat, is.yearly = TRUE)
```

### Compare plots
```{r}
g2 <- NULL
g2[[1]] <- plot(out3, is.yearly=FALSE, is.subnational=TRUE) + ggtitle("Subnational period model")
g2[[2]] <- plot(out4, is.yearly=TRUE, is.subnational=TRUE) + ggtitle("Subnational yearly model")
grid.arrange(grobs=g2, ncol = 2)
```

### Map visualization of changes across time

```{r, fig.width=9, fig.height=9}
mapPlot(data = subset(out4, is.yearly==F), geo = DemoMap$geo,
        variables=c("Year"), values = c("med"), by.data = "District", by.geo = "NAME_final", is.long=TRUE)
```



## Simple spatial smoothing examples
In this section we show two simple spatial smoothing example using data created from the model survey data, and a Kenya Admin 1 map with 8 regions.
```{r}
data(DemoData2)
data(DemoMap2)
```

The `DemoData2` dataset contains the survey information and two response variables, age and tobacco usage. 
```{r}
head(DemoData2)
```

### Normal model
We first generate some synthetic normally distributed variable for height for each observation. Suppose we denote the height of observation $k$ in area $i$ to be $x_{ik}$, and the associated design weight to be $w_{ik}$. Under the design-based approach to inference, we can calculate the weighted estimator of mean height to be 
\[
  \hat{\mu_i} = \frac{\sum_k w_{ik}x_{ik}}{\sum_k w_{ik}}
\]
and the associated variance $\widehat{var}(\hat{\mu_i})$. We then use INLA to fit the following Bayesian hierarchical model:
\begin{eqnarray*}
\hat{\mu}_i &\sim & \mbox{Normal}( \mu_i, \widehat{var}(\hat{\mu_i}) )\\
\mu_i &=& \beta + \epsilon_i+\delta_i,\\
\epsilon_i &\sim & \mbox{Normal}(0,\sigma_\epsilon^2)\\
\delta_i &\sim & \mbox{ICAR}(\sigma_\delta^2)
\end{eqnarray*}

To simulate from this generative model, we first simulate from the ICAR random fields as follows
```{r}
set.seed(123)
sim.Q <- function(Q){
  eigenQ <- eigen(Q)
  rankQ <- qr(Q)$rank
  sim <- as.vector(eigenQ$vectors[,1:rankQ] %*% 
           matrix(
             rnorm(rep(1, rankQ), rep(0, rankQ), 1/sqrt(eigenQ$values[1:rankQ])),
           ncol = 1))
  sim
}
Q <- DemoMap2$Amat * -1
diag(Q) <- 0
diag(Q) <- -1 * apply(Q, 2, sum)
struct.error <- sim.Q(Q) 
```
We generate the mean height for each region by 

```{r}
mu <- 70 + struct.error
regions <- colnames(DemoMap2$Amat)
```


We generate the data by
```{r}
DemoData2$height <- rnorm(dim(DemoData2)[1])*8 + mu[match(DemoData2$region, regions)]
```


We can use the `fitspace()` function to obtain both the survey-weighted direct estimates and the smoothed estimates from INLA.

```{r}
fit <- fitSpace(data=DemoData2, geo=DemoMap2$geo, Amat=DemoMap2$Amat,
                family="gaussian", responseVar="height", strataVar="strata",
                weightVar="weights", regionVar="region", 
                clusterVar = "~clustid+id", 
                hyper=NULL, CI = 0.95)
```



The posterior median of the structured random effects can be obtained from:
```{r, fig.width=5, fig.height=5, out.width = '50%'}
fit$fit$summary.random$reg.struct[, "0.5quant"]
```

We can compare the posterior of the structured random effects with the truth values from the simulation.
```{r, fig.width=5, fig.height=5, out.width = '50%'}
lim <- range(c(struct.error, fit$fit$summary.random$reg.struct[, "0.025quant"],
               fit$fit$summary.random$reg.struct[, "0.975quant"]))
plot(struct.error, fit$fit$summary.random$reg.struct[, "0.5quant"],  xlab = "Structured random effects", ylab = "Posterior median", xlim = lim, ylim = lim)
segments(x0 = struct.error, x1 = struct.error,
         y0 = fit$fit$summary.random$reg.struct[, "0.025quant"], 
         y1 = fit$fit$summary.random$reg.struct[, "0.975quant"])
abline(c(0, 1))
```


The direct estimates of the average height, i.e., $\hat{\mu}_i$ accounting for survey design are 
```{r}
fit$HT[, c("HT.est", "HT.sd", "region")]
```

The posterior summaries of $\mu_i|\hat{\mu}_i$ can be obtained by 
```{r}
fit$smooth[, c("mean", "sd", "median", "lower", "upper", "region")]
```

We can compare the direct and smoothed estimates and their standard errors.
```{r}
par(mfrow = c(1, 2))
lim <- range(c(fit$HT$HT.est, fit$smooth$mean))
plot(fit$HT$HT.est, fit$smooth$mean, xlim = lim, ylim = lim, xlab = "Direct estimates", ylab = "Posterior mean")
abline(c(0, 1))
lim <- range(c(fit$HT$HT.sd, fit$smooth$sd))
plot(fit$HT$HT.sd, fit$smooth$sd, xlim = lim, ylim = lim, xlab = "Direct SE", ylab = "Posterior SD")
abline(c(0, 1))
```



We can also compare the direct and smoothed estimates on the map.
```{r, fig.width=15, fig.height=5}
combined <- merge(fit$HT, fit$smooth, by = "region")
combined$truth <- mu[match(combined$region, regions)]
mapPlot(data = combined, geo = DemoMap2$geo, 
        variables=c("truth", "HT.est", "median"), 
        labels = c("True mean", "Direct Estimates", "Posterior Median"),
        by.data = "region", by.geo = "NAME_final", is.long=FALSE)
```


### Binary model with logistic link
Similar as in the previous subsection, suppose we denote the tobacco usage of observation $k$ in area $i$ to be $y_{ik}$, and the associated design weight to be $w_{ik}$. Under the design-based approach to inference, we can calculate the weighted estimator of prevalence to be 
\[
  \hat{p_i} = \frac{\sum_k w_{ik}y_{ik}}{\sum_k w_{ik}}
\]
and the associated variance $\widehat{var}(\hat{p_i})$. By delta method, if we denote $\hat\theta_{i} = \log(\frac{\hat{p}_i}{1-\hat{p}_i})$, the asymptotic distribution of $\hat\theta_{i}$ is 
\[
  \hat{\theta}_i \sim \mbox{Normal}(\log(\frac{p_i}{1-p_i}), \hat V_i), \;\;\;\; \hat V_i = \frac{\widehat{var}(\hat{p_i})}{(\hat{p}_i (1 - \hat{p}_i))^2}
\]
We then use INLA to fit the following Bayesian hierarchical model:
\begin{eqnarray*}
\hat{\theta}_i &=& \log\left( \dfrac{\hat{p_i}}{1-\hat{p_i}} \right) \sim \mbox{Normal}( \theta_i,\hat{V}_i )\\
\theta_i &=& \beta + \epsilon_i+\delta_i,\\
\epsilon_i &\sim & \mbox{Normal}(0,\sigma_\epsilon^2)\\
\delta_i &\sim & \mbox{ICAR}(\sigma_\delta^2)
\end{eqnarray*}

We can use the `fitspace()` function to obtain both the survey-weighted direct estimates and the smoothed estimates from INLA.

```{r}
fit <- fitSpace(data=DemoData2, geo=DemoMap2$geo, Amat=DemoMap2$Amat,
                family="binomial", responseVar="tobacco.use",
                strataVar="strata", weightVar="weights", regionVar="region",
                clusterVar = "~clustid+id", hyper=NULL, CI = 0.95)
```


The direct estimates of the prevalence of tobacco usage, i.e., $\hat{p}_i$ accounting for survey design are 
```{r}
fit$HT[, c("HT.est.original", "HT.variance.original", "region")]
```

The logit transformed direct estimates, $\hat{\theta}_i$ and the associated asymptotic standard deviations are 
```{r}
fit$HT[, c("HT.est", "HT.sd", "region")]
```

The posterior summaries of $\theta_i|\hat{\theta}_i$ can be obtained by 
```{r}
fit$smooth[, c("mean", "sd", "median", "lower", "upper", "region")]
```

The posterior summaries of  $p_i|\hat{\theta}_i$ can be obtained by 

```{r}
fit$smooth[, c("mean.trans", "sd.trans", "median.trans", "lower.trans", "upper.trans", "region")]
```

We can now compare the direct and smoothed variables on the map.
```{r}
combined <- merge(fit$HT, fit$smooth, by = "region")
mapPlot(data = combined, geo = DemoMap2$geo, variables=c("HT.est", "median"),
        labels = c("Direct Estimates", "Posterior Median"), 
        by.data = "region", by.geo = "NAME_final", is.long=FALSE)
```

